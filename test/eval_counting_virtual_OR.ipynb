{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Weakly Supervised Instance Segmentation using Class Peak Response \n",
    "### Evaluation code of object counting in COCO\n",
    "\n",
    "Published Results: mRMSE 0.29, mRMSE-nz 1.14, m-relRMSE 0.17, m-relRMSE-nz 0.61 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import os\n",
    "import json\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from scipy.misc import imresize\n",
    "import matplotlib.pyplot as plt\n",
    "from nest import modules, run_tasks\n",
    "from collections import OrderedDict\n",
    "import torch.nn.functional as F\n",
    "from PIL import Image\n",
    "\n",
    "## make sure you have correctly install cocoapi, https://github.com/cocodataset/cocoapi\n",
    "from pycocotools.coco import COCO\n",
    "from pycocotools.cocoeval import COCOeval\n",
    "import pycocotools.mask as mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No module named 'pyinn'. The package \"prm\" under namespace \"prm\" could not be imported. Try to execute \"conda install opencv\" to install the missing dependency.\n",
      "calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "import torch\n",
    "def mrmse(non_zero, count_pred, count_gt): \n",
    "    nzero_mask=torch.ones(count_gt.size()) \n",
    "    if non_zero==1:\n",
    "        nzero_mask=torch.zeros(count_gt.size())\n",
    "        nzero_mask[count_gt!=0]=1 \n",
    "    mrmse = torch.pow(count_pred - count_gt, 2) \n",
    "    mrmse = torch.mul(mrmse, nzero_mask) \n",
    "    mrmse = torch.sum(mrmse, 0) \n",
    "    nzero = torch.sum(nzero_mask, 0) \n",
    "    mrmse = torch.div(mrmse, nzero) \n",
    "    # Alteration to set nan values to 0 - J.I. \n",
    "    mrmse[torch.isnan(mrmse)] = 0 \n",
    "    mrmse = torch.sqrt(mrmse)  \n",
    "    mrmse = torch.mean(mrmse) \n",
    "    return mrmse\n",
    "\n",
    "def rel_mrmse(non_zero,count_pred, count_gt):\n",
    "    nzero_mask=torch.ones(count_gt.size())\n",
    "    if non_zero==1:\n",
    "        nzero_mask=torch.zeros(count_gt.size())\n",
    "        nzero_mask[count_gt!=0]=1\n",
    "    num = torch.pow(count_pred - count_gt, 2)\n",
    "    denom = count_gt.clone()\n",
    "    denom = denom+1\n",
    "    rel_mrmse = torch.div(num, denom)\n",
    "    rel_mrmse = torch.mul(rel_mrmse, nzero_mask)\n",
    "    rel_mrmse = torch.sum(rel_mrmse, 0)\n",
    "    nzero = torch.sum(nzero_mask, 0)\n",
    "    rel_mrmse = torch.div(rel_mrmse, nzero)\n",
    "    # Alteration to set nan values to 0 - J.I. \n",
    "    rel_mrmse[torch.isnan(rel_mrmse)] = 0 \n",
    "    rel_mrmse = torch.sqrt(rel_mrmse)\n",
    "    rel_mrmse = torch.mean(rel_mrmse)\n",
    "    return rel_mrmse\n",
    "\n",
    "# image pre-processor\n",
    "image_size = 448\n",
    "transformer = modules.image_transform(\n",
    "    image_size = [image_size, image_size],\n",
    "    augmentation = dict(),\n",
    "    mean = [0.485, 0.456, 0.406],\n",
    "    std = [0.229, 0.224, 0.225])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=1.45s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "source": [
    "## load ground truth\n",
    "# coco_path='../../../../../../../media/James/BigData/COCO/'\n",
    "coco_path='../../../../../../../media/James/BigData/Virtual_OR_Dataset'\n",
    "#'/raid/xiaoke/MSCOCO/coco'\n",
    " \n",
    "# cocoGt=COCO(coco_path+'/annotations/virtual_OR_dataset_annotation.json')\n",
    "cocoGt=COCO(coco_path+'/annotations/virtual_OR_test.json')\n",
    "image_ids=cocoGt.getImgIds()\n",
    "\n",
    "catids=cocoGt.getCatIds()\n",
    "\n",
    "num_classes=len(catids)\n",
    "catid2index={}\n",
    "for i,cid in enumerate(catids):\n",
    "    catid2index[cid]=i\n",
    "annids=cocoGt.getAnnIds()\n",
    "class_labels = OrderedDict()\n",
    "for id in annids:\n",
    "    anns=cocoGt.loadAnns(id)\n",
    "    for i in range(len(anns)):\n",
    "        ann=anns[i]\n",
    "        name=ann['image_id']\n",
    "        if name not in class_labels:\n",
    "            class_labels[name]=np.zeros(num_classes)\n",
    "        category_id=ann['category_id']\n",
    "        class_labels[name][catid2index[category_id]]+=1\n",
    "\n",
    "image_list_all=list(class_labels.keys())\n",
    "gt_counts_all=[gt[1] for gt in list(class_labels.items())]\n",
    "gt_counts_all=np.array(gt_counts_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No module named 'pyinn'. The package \"prm\" under namespace \"prm\" could not be imported. Try to execute \"conda install opencv\" to install the missing dependency.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'Could not find the Nest module \"fc_resnet50\".'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-b742ff6839b0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m## load model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mbackbone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc_resnet50\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchannels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpretrained\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m model = modules.peak_response_mapping(backbone,enable_peak_stimulation=True,peak_stimulation='addedmodule5',\n\u001b[1;32m     10\u001b[0m                                      sub_pixel_locating_factor=1)\n",
      "\u001b[0;32m~/.conda/envs/pytorch/lib/python3.6/site-packages/nest/logger.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     57\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcatch_warnings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecord\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mwarning_list\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m                 \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msimplefilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'always'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m                 \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mwarning_list\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m                     \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/pytorch/lib/python3.6/site-packages/nest/modules.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    758\u001b[0m                 \u001b[0mmatches\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    759\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmatches\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 760\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Could not find the Nest module \"%s\".'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    761\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmatches\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    762\u001b[0m             warnings.warn('Multiple Nest modules with this name have been found. \\n'\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Could not find the Nest module \"fc_resnet50\".'"
     ]
    }
   ],
   "source": [
    "## use the first half as validation and second half as test\n",
    "index=5#int(40137/2)\n",
    "print(index)\n",
    "image_list=image_list_all[index:]\n",
    "gt_count=gt_counts_all[index:]\n",
    "\n",
    "## load model\n",
    "backbone = modules.fc_resnet50(channels=30, pretrained=False)\n",
    "model = modules.peak_response_mapping(backbone,enable_peak_stimulation=True,peak_stimulation='addedmodule5',\n",
    "                                     sub_pixel_locating_factor=1)\n",
    "model = nn.DataParallel(model)\n",
    "checkpoint = torch.load('../../../../../../../media/James/BigData/CountSeg_output/vOR_counting/model_latest.pt')#\n",
    "#('../models/counting/coco14.pt') \n",
    "model_dict = model.state_dict()\n",
    "trained_dict = {k: v for k, v in checkpoint['model'].items() if k in model_dict}\n",
    "model_dict.update(trained_dict)\n",
    "model.load_state_dict(model_dict)\n",
    "model = model.module.cuda()\n",
    "#print(model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate the new implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-73e9e7b26cf2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mwidth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mraw_img\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0minput_var\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransformer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_img\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequires_grad_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0mconfidence\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mclass_response_map1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpeak\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_var\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mconfidence\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfidence\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "## counting\n",
    "pred_class=[]\n",
    "pred_count=[]\n",
    "\n",
    "for index_d,ima in enumerate(image_list):\n",
    "    if index_d%10000==0:\n",
    "        print(index_d)\n",
    "    raw_img = Image.open(coco_path+'/images/'+'0'*(12-len(str(ima)))+str(ima)+'.png').convert('RGB')\n",
    "    width, height=raw_img.size \n",
    "    input_var = transformer(raw_img).unsqueeze(0).cuda().requires_grad_()\n",
    "    model = model.eval()\n",
    "    confidence,class_response_map1,peak = model(input_var,1)\n",
    "    confidence=confidence.cpu().detach().numpy()\n",
    "    count_one = F.adaptive_avg_pool2d(class_response_map1, 1).squeeze(2).squeeze(2).detach().cpu().numpy()[0]\n",
    "    confidence[confidence<0]=0\n",
    "    confidence=confidence[0]\n",
    "    confidence[confidence>0]=1\n",
    "    pred_class.append(confidence)\n",
    "    pred_count.append(np.round(confidence*count_one))\n",
    "pred_count=np.array(pred_count)\n",
    "\n",
    "print('mRMSE', mrmse(0,torch.from_numpy(pred_count).float(), torch.from_numpy(gt_count).float()))\n",
    "print('mRMSE_nz', mrmse(1,torch.from_numpy(pred_count).float(), torch.from_numpy(gt_count).float()))\n",
    "print('rel_mRMSE', rel_mrmse(0,torch.from_numpy(pred_count).float(), torch.from_numpy(gt_count).float()))\n",
    "print('rel_mRMSE_nz', rel_mrmse(1,torch.from_numpy(pred_count).float(), torch.from_numpy(gt_count).float()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # parsed_json = (json.loads(json_data))\n",
    "\n",
    "# with open(coco_path+'/annotations/virtual_OR_dataset_annotation(v2).json', 'r') as f:\n",
    "#     distros_dict = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# distros_dict['categories']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index_d,ima in enumerate(image_list):\n",
    "    raw_img = Image.open(coco_path+'/images/'+'0'*(12-len(str(ima)))+str(ima)+'.png').convert('RGB')\n",
    "    width, height=raw_img.size \n",
    "    input_var = transformer(raw_img).unsqueeze(0).cuda().requires_grad_()\n",
    "    model = model.eval()\n",
    "    confidence,class_response_map1,peak = model(input_var,1)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "class_ID = 0\n",
    "IMG = class_response_map1[0][class_ID].cpu().detach().numpy()\n",
    "# Image.fromarray(IMG )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG = IMG + 1\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "ssap_exp_config": {
   "error_alert": "Error Occurs!",
   "initial": [],
   "max_iteration": 1,
   "recv_id": "",
   "running": [],
   "summary": [],
   "version": "1.1.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
