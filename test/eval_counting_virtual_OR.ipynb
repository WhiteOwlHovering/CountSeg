{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Weakly Supervised Instance Segmentation using Class Peak Response \n",
    "### Evaluation code of object counting in COCO\n",
    "\n",
    "Published Results: mRMSE 0.29, mRMSE-nz 1.14, m-relRMSE 0.17, m-relRMSE-nz 0.61 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import os\n",
    "import json\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from scipy.misc import imresize\n",
    "import matplotlib.pyplot as plt\n",
    "from nest import modules, run_tasks\n",
    "from collections import OrderedDict\n",
    "import torch.nn.functional as F\n",
    "from PIL import Image\n",
    "\n",
    "## make sure you have correctly install cocoapi, https://github.com/cocodataset/cocoapi\n",
    "from pycocotools.coco import COCO\n",
    "from pycocotools.cocoeval import COCOeval\n",
    "import pycocotools.mask as mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "import torch\n",
    "def mrmse(non_zero, count_pred, count_gt): \n",
    "    nzero_mask=torch.ones(count_gt.size()) \n",
    "    if non_zero==1:\n",
    "        nzero_mask=torch.zeros(count_gt.size())\n",
    "        nzero_mask[count_gt!=0]=1 \n",
    "    mrmse = torch.pow(count_pred - count_gt, 2) \n",
    "    mrmse = torch.mul(mrmse, nzero_mask) \n",
    "    mrmse = torch.sum(mrmse, 0) \n",
    "    nzero = torch.sum(nzero_mask, 0) \n",
    "    mrmse = torch.div(mrmse, nzero) \n",
    "    # Alteration to set nan values to 0 - J.I. \n",
    "    mrmse[torch.isnan(mrmse)] = 0 \n",
    "    mrmse = torch.sqrt(mrmse)  \n",
    "    mrmse = torch.mean(mrmse) \n",
    "    return mrmse\n",
    "\n",
    "def rel_mrmse(non_zero,count_pred, count_gt):\n",
    "    nzero_mask=torch.ones(count_gt.size())\n",
    "    if non_zero==1:\n",
    "        nzero_mask=torch.zeros(count_gt.size())\n",
    "        nzero_mask[count_gt!=0]=1\n",
    "    num = torch.pow(count_pred - count_gt, 2)\n",
    "    denom = count_gt.clone()\n",
    "    denom = denom+1\n",
    "    rel_mrmse = torch.div(num, denom)\n",
    "    rel_mrmse = torch.mul(rel_mrmse, nzero_mask)\n",
    "    rel_mrmse = torch.sum(rel_mrmse, 0)\n",
    "    nzero = torch.sum(nzero_mask, 0)\n",
    "    rel_mrmse = torch.div(rel_mrmse, nzero)\n",
    "    # Alteration to set nan values to 0 - J.I. \n",
    "    rel_mrmse[torch.isnan(rel_mrmse)] = 0 \n",
    "    rel_mrmse = torch.sqrt(rel_mrmse)\n",
    "    rel_mrmse = torch.mean(rel_mrmse)\n",
    "    return rel_mrmse\n",
    "\n",
    "# image pre-processor\n",
    "image_size = 448\n",
    "transformer = modules.image_transform(\n",
    "    image_size = [image_size, image_size],\n",
    "    augmentation = dict(),\n",
    "    mean = [0.485, 0.456, 0.406],\n",
    "    std = [0.229, 0.224, 0.225])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.01s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "source": [
    "## load ground truth\n",
    "# coco_path='../../../../../../../media/James/BigData/COCO/'\n",
    "coco_path='../../../../../../../media/James/BigData/Virtual_OR_Dataset'\n",
    "#'/raid/xiaoke/MSCOCO/coco'\n",
    "# cocoGt=COCO(coco_path+'/annotations/virtual_OR_dataset_annotation.json')\n",
    "cocoGt=COCO(coco_path+'/annotations/virtual_OR_dataset_annotation(v2).json')\n",
    "image_ids=cocoGt.getImgIds()\n",
    "\n",
    "catids=cocoGt.getCatIds()\n",
    "\n",
    "num_classes=len(catids)\n",
    "catid2index={}\n",
    "for i,cid in enumerate(catids):\n",
    "    catid2index[cid]=i\n",
    "annids=cocoGt.getAnnIds()\n",
    "class_labels = OrderedDict()\n",
    "for id in annids:\n",
    "    anns=cocoGt.loadAnns(id)\n",
    "    for i in range(len(anns)):\n",
    "        ann=anns[i]\n",
    "        name=ann['image_id']\n",
    "        if name not in class_labels:\n",
    "            class_labels[name]=np.zeros(num_classes)\n",
    "        category_id=ann['category_id']\n",
    "        class_labels[name][catid2index[category_id]]+=1\n",
    "\n",
    "image_list_all=list(class_labels.keys())\n",
    "gt_counts_all=[gt[1] for gt in list(class_labels.items())]\n",
    "gt_counts_all=np.array(gt_counts_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "<function PeakResponseMapping._median_filter at 0x7f9db8e089d8>\n",
      "addedmodule5\n",
      "enable_peak_stimulation on\n"
     ]
    }
   ],
   "source": [
    "## use the first half as validation and second half as test\n",
    "index=5#int(40137/2)\n",
    "print(index)\n",
    "image_list=image_list_all[index:]\n",
    "gt_count=gt_counts_all[index:]\n",
    "\n",
    "## load model\n",
    "backbone = modules.fc_resnet50(channels=30, pretrained=False)\n",
    "model = modules.peak_response_mapping(backbone,enable_peak_stimulation=True,peak_stimulation='addedmodule5',\n",
    "                                     sub_pixel_locating_factor=1)\n",
    "model = nn.DataParallel(model)\n",
    "# checkpoint = torch.load('../models/counting/coco14.pt') \n",
    "# model_dict = model.state_dict()\n",
    "trained_dict = {k: v for k, v in checkpoint['model'].items() if k in model_dict}\n",
    "model_dict.update(trained_dict)\n",
    "# model.load_state_dict(model_dict)\n",
    "model = model.module.cuda()\n",
    "#print(model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate the new implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "mrmse pow tensor([[25.,  9., 16., 16.,  0.,  4.,  0.,  9.,  4.,  1.],\n",
      "        [25.,  9.,  9., 16.,  0.,  1.,  0.,  9.,  4.,  1.],\n",
      "        [25.,  9.,  9.,  9.,  0.,  4.,  0.,  9.,  4.,  1.],\n",
      "        [25., 16.,  9., 16.,  0.,  4.,  0.,  9.,  4.,  1.],\n",
      "        [25.,  9.,  9., 16.,  0.,  4.,  0.,  4.,  4.,  1.],\n",
      "        [25., 16.,  9., 16.,  0.,  4.,  0.,  9.,  4.,  1.],\n",
      "        [25., 16.,  9., 16.,  0.,  1.,  0.,  9.,  4.,  1.],\n",
      "        [25., 16.,  9., 16.,  0.,  4.,  0.,  4.,  4.,  1.],\n",
      "        [25.,  9.,  9., 16.,  0.,  4.,  1.,  9.,  4.,  1.],\n",
      "        [25.,  9.,  9., 16.,  0.,  1.,  1.,  9.,  4.,  1.],\n",
      "        [25.,  9.,  9.,  9.,  0.,  4.,  1.,  9.,  4.,  1.],\n",
      "        [25.,  9.,  9., 16.,  1.,  4.,  0.,  9.,  4.,  1.],\n",
      "        [25., 16.,  9., 16.,  1.,  4.,  0.,  9.,  4.,  1.],\n",
      "        [25.,  9.,  9., 16.,  1.,  4.,  1.,  9.,  4.,  1.],\n",
      "        [25.,  9.,  9., 16.,  4.,  4.,  0.,  9.,  4.,  1.]])\n",
      "mrmse mul tensor([[25.,  9., 16., 16.,  0.,  4.,  0.,  9.,  4.,  1.],\n",
      "        [25.,  9.,  9., 16.,  0.,  1.,  0.,  9.,  4.,  1.],\n",
      "        [25.,  9.,  9.,  9.,  0.,  4.,  0.,  9.,  4.,  1.],\n",
      "        [25., 16.,  9., 16.,  0.,  4.,  0.,  9.,  4.,  1.],\n",
      "        [25.,  9.,  9., 16.,  0.,  4.,  0.,  4.,  4.,  1.],\n",
      "        [25., 16.,  9., 16.,  0.,  4.,  0.,  9.,  4.,  1.],\n",
      "        [25., 16.,  9., 16.,  0.,  1.,  0.,  9.,  4.,  1.],\n",
      "        [25., 16.,  9., 16.,  0.,  4.,  0.,  4.,  4.,  1.],\n",
      "        [25.,  9.,  9., 16.,  0.,  4.,  1.,  9.,  4.,  1.],\n",
      "        [25.,  9.,  9., 16.,  0.,  1.,  1.,  9.,  4.,  1.],\n",
      "        [25.,  9.,  9.,  9.,  0.,  4.,  1.,  9.,  4.,  1.],\n",
      "        [25.,  9.,  9., 16.,  1.,  4.,  0.,  9.,  4.,  1.],\n",
      "        [25., 16.,  9., 16.,  1.,  4.,  0.,  9.,  4.,  1.],\n",
      "        [25.,  9.,  9., 16.,  1.,  4.,  1.,  9.,  4.,  1.],\n",
      "        [25.,  9.,  9., 16.,  4.,  4.,  0.,  9.,  4.,  1.]])\n",
      "mrmse sum tensor([375., 170., 142., 226.,   7.,  51.,   4., 125.,  60.,  15.])\n",
      "mrmse sum tensor([375., 170., 142., 226.,   7.,  51.,   4., 125.,  60.,  15.])\n",
      "mrmse div tensor([25.0000, 11.3333,  9.4667, 15.0667,  0.4667,  3.4000,  0.2667,  8.3333,\n",
      "         4.0000,  1.0000])\n",
      "mrmse div # tensor([25.0000, 11.3333,  9.4667, 15.0667,  0.4667,  3.4000,  0.2667,  8.3333,\n",
      "         4.0000,  1.0000])\n",
      "mrmse sqrt tensor([5.0000, 3.3665, 3.0768, 3.8816, 0.6831, 1.8439, 0.5164, 2.8868, 2.0000,\n",
      "        1.0000])\n",
      "mrmse mean tensor(2.4255)\n",
      "mRMSE tensor(2.4255)\n",
      "mrmse pow tensor([[25.,  9., 16., 16.,  0.,  4.,  0.,  9.,  4.,  1.],\n",
      "        [25.,  9.,  9., 16.,  0.,  1.,  0.,  9.,  4.,  1.],\n",
      "        [25.,  9.,  9.,  9.,  0.,  4.,  0.,  9.,  4.,  1.],\n",
      "        [25., 16.,  9., 16.,  0.,  4.,  0.,  9.,  4.,  1.],\n",
      "        [25.,  9.,  9., 16.,  0.,  4.,  0.,  4.,  4.,  1.],\n",
      "        [25., 16.,  9., 16.,  0.,  4.,  0.,  9.,  4.,  1.],\n",
      "        [25., 16.,  9., 16.,  0.,  1.,  0.,  9.,  4.,  1.],\n",
      "        [25., 16.,  9., 16.,  0.,  4.,  0.,  4.,  4.,  1.],\n",
      "        [25.,  9.,  9., 16.,  0.,  4.,  1.,  9.,  4.,  1.],\n",
      "        [25.,  9.,  9., 16.,  0.,  1.,  1.,  9.,  4.,  1.],\n",
      "        [25.,  9.,  9.,  9.,  0.,  4.,  1.,  9.,  4.,  1.],\n",
      "        [25.,  9.,  9., 16.,  1.,  4.,  0.,  9.,  4.,  1.],\n",
      "        [25., 16.,  9., 16.,  1.,  4.,  0.,  9.,  4.,  1.],\n",
      "        [25.,  9.,  9., 16.,  1.,  4.,  1.,  9.,  4.,  1.],\n",
      "        [25.,  9.,  9., 16.,  4.,  4.,  0.,  9.,  4.,  1.]])\n",
      "mrmse mul tensor([[ 0.,  0., 16.,  0.,  0.,  0.,  0.,  0.,  4.,  0.],\n",
      "        [ 0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  4.,  0.],\n",
      "        [ 0.,  0.,  0.,  9.,  0.,  0.,  0.,  0.,  4.,  0.],\n",
      "        [ 0., 16.,  0.,  0.,  0.,  0.,  0.,  0.,  4.,  0.],\n",
      "        [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  4.,  4.,  0.],\n",
      "        [ 0., 16.,  0.,  0.,  0.,  0.,  0.,  0.,  4.,  0.],\n",
      "        [ 0., 16.,  0.,  0.,  0.,  1.,  0.,  0.,  4.,  0.],\n",
      "        [ 0., 16.,  0.,  0.,  0.,  0.,  0.,  4.,  4.,  0.],\n",
      "        [ 0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  4.,  0.],\n",
      "        [ 0.,  0.,  0.,  0.,  0.,  1.,  1.,  0.,  4.,  0.],\n",
      "        [ 0.,  0.,  0.,  9.,  0.,  0.,  1.,  0.,  4.,  0.],\n",
      "        [ 0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  4.,  0.],\n",
      "        [ 0., 16.,  0.,  0.,  1.,  0.,  0.,  0.,  4.,  0.],\n",
      "        [ 0.,  0.,  0.,  0.,  1.,  0.,  1.,  0.,  4.,  0.],\n",
      "        [ 0.,  0.,  0.,  0.,  4.,  0.,  0.,  0.,  4.,  0.]])\n",
      "mrmse sum tensor([ 0., 80., 16., 18.,  7.,  3.,  4.,  8., 60.,  0.])\n",
      "mrmse sum tensor([ 0., 80., 16., 18.,  7.,  3.,  4.,  8., 60.,  0.])\n",
      "mrmse div tensor([    nan, 16.0000, 16.0000,  9.0000,  1.7500,  1.0000,  1.0000,  4.0000,\n",
      "         4.0000,     nan])\n",
      "mrmse div # tensor([ 0.0000, 16.0000, 16.0000,  9.0000,  1.7500,  1.0000,  1.0000,  4.0000,\n",
      "         4.0000,  0.0000])\n",
      "mrmse sqrt tensor([0.0000, 4.0000, 4.0000, 3.0000, 1.3229, 1.0000, 1.0000, 2.0000, 2.0000,\n",
      "        0.0000])\n",
      "mrmse mean tensor(1.8323)\n",
      "mRMSE_nz tensor(1.8323)\n"
     ]
    }
   ],
   "source": [
    "## counting\n",
    "pred_class=[]\n",
    "pred_count=[]\n",
    "\n",
    "for index_d,ima in enumerate(image_list):\n",
    "    if index_d%10000==0:\n",
    "        print(index_d)\n",
    "    raw_img = Image.open(coco_path+'/images/val/'+'0'*(12-len(str(ima)))+str(ima)+'.png').convert('RGB')\n",
    "    width, height=raw_img.size \n",
    "    input_var = transformer(raw_img).unsqueeze(0).cuda().requires_grad_()\n",
    "    model = model.eval()\n",
    "    confidence,class_response_map1,peak = model(input_var,1)\n",
    "    confidence=confidence.cpu().detach().numpy()\n",
    "    count_one = F.adaptive_avg_pool2d(class_response_map1, 1).squeeze(2).squeeze(2).detach().cpu().numpy()[0]\n",
    "    confidence[confidence<0]=0\n",
    "    confidence=confidence[0]\n",
    "    confidence[confidence>0]=1\n",
    "    pred_class.append(confidence)\n",
    "    pred_count.append(np.round(confidence*count_one))\n",
    "pred_count=np.array(pred_count)\n",
    "\n",
    "print('mRMSE', mrmse(0,torch.from_numpy(pred_count).float(), torch.from_numpy(gt_count).float()))\n",
    "print('mRMSE_nz', mrmse(1,torch.from_numpy(pred_count).float(), torch.from_numpy(gt_count).float()))\n",
    "print('rel_mRMSE', rel_mrmse(0,torch.from_numpy(pred_count).float(), torch.from_numpy(gt_count).float()))\n",
    "print('rel_mRMSE_nz', rel_mrmse(1,torch.from_numpy(pred_count).float(), torch.from_numpy(gt_count).float()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "virtual_OR_dataset_annotation.csv   virtual_OR_dataset_annotation(v2).json\r\n",
      "virtual_OR_dataset_annotation.json\r\n"
     ]
    }
   ],
   "source": [
    "!ls ../../../../../../../media/James/BigData/Virtual_OR_Dataset/annotations/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # parsed_json = (json.loads(json_data))\n",
    "\n",
    "# with open(coco_path+'/annotations/virtual_OR_dataset_annotation(v2).json', 'r') as f:\n",
    "#     distros_dict = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# distros_dict['categories']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "ssap_exp_config": {
   "error_alert": "Error Occurs!",
   "initial": [],
   "max_iteration": 1,
   "recv_id": "",
   "running": [],
   "summary": [],
   "version": "1.1.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
